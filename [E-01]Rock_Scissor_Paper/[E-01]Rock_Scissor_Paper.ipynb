{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3925a58a",
   "metadata": {},
   "source": [
    "# EP 01. 인공지능과 가위바위보 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955693d2",
   "metadata": {},
   "source": [
    "사실 별 거 아닌데 !!!!!!!!!! 성능 안 나와서 노트북 뿌실 뻔 함 !!!!!!! <br/>\n",
    "** 삽질을 많이 해서 가독성이 떨어질 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86959487",
   "metadata": {},
   "source": [
    "# 1. 데이터 불러오기\n",
    "저는 lms에 나와있는 https://teachablemachine.withgoogle.com/ 사이트를 이용해 가위 바위 보 이미지를 직접 촬영했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d588bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -uq \"train1/scissor.zip\" -d \"train1/scissor\"\n",
    "# !unzip -uq \"train1/paper.zip\" -d \"train1/paper\"\n",
    "# !unzip -uq \"train1/rock.zip\" -d \"train1/rock\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0316f748",
   "metadata": {},
   "source": [
    "## 1-1. 필요한 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "049f2a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb344813",
   "metadata": {},
   "source": [
    "## 1-2. 이미지 resize\n",
    "다운로드 받은 이미지의 원래 크기는 224x224였고 이를 28x28로 변경하려 한다.\n",
    "\n",
    "🧤 가위, 바위, 보의 이미지는 각각 100장씩, 총 300장이다. <br/>\n",
    "🧤 이미지들이 잘 resize 되었고, 새로 save도 되었다. <br/>\n",
    "**+여기서 바로 save하지 않고 원본 데이터는 따로 저장했으면 더 좋았을듯!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ef443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_path):\n",
    "    images = glob.glob(img_path + '/*.jpg') # jpg로 끝나는 모든 파일\n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "    \n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장\n",
    "    target_size = (28, 28)\n",
    "    for img in images:\n",
    "        old_img = Image.open(img) # 원본\n",
    "        new_img = old_img.resize(target_size, Image.ANTIALIAS) # resize\n",
    "        new_img.save(img, \"JPEG\") # 저장\n",
    "        \n",
    "    print(len(images), \" images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da86e108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "=========================\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "=========================\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여 resize\n",
    "s_path = './train1/scissor/scissor'\n",
    "resize_images(s_path)\n",
    "print('가위 이미지 resize 완료!')\n",
    "print('=========================')\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여 resize\n",
    "r_path = './train1/rock/rock'\n",
    "resize_images(r_path)\n",
    "print('바위 이미지 resize 완료!')\n",
    "print('=========================')\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여 resize\n",
    "p_path = './train1/paper/paper'\n",
    "resize_images(p_path)\n",
    "print('보 이미지 resize 완료!')\n",
    "print('=========================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be10f4ed",
   "metadata": {},
   "source": [
    "## 1-3. 이미지 불러오기\n",
    "\n",
    "#### 가위(0), 바위(1), 보(2)로 클래스를 할당\n",
    "\n",
    "- train data set은 총 300개이고, 크기는 (28, 28)로 잘 조정되었음을 알 수 있다.\n",
    "- 컬러 이미지이므로 마지막 채널 값은 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46c0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path, number_of_data):\n",
    "    \n",
    "    # 가위(0), 바위(1), 보(2)\n",
    "    img_size = 28\n",
    "    color = 3\n",
    "    \n",
    "    # 이미지 데이터와 라벨(가위(0), 바위(1), 보(2)) 데이터를 담을 행렬(matrix) 영역 생성\n",
    "    imgs = np.zeros(number_of_data * img_size * img_size * color, dtype=np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    labels = np.zeros(number_of_data, dtype=np.int32)\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for file in glob.iglob(img_path + 'scissor/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 0 # 가위(0)\n",
    "        idx = idx + 1\n",
    "    \n",
    "    for file in glob.iglob(img_path + 'rock/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 1 # 바위(1)\n",
    "        idx = idx + 1\n",
    "    \n",
    "    for file in glob.iglob(img_path + 'paper/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 2 # 보(2)\n",
    "        idx = idx + 1\n",
    "    \n",
    "    print('학습 데이터(x_train)의 이미지 개수는 ', idx, '입니다.')\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4308f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터(x_train)의 이미지 개수는  300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "img_dir_path = './train1/'\n",
    "(x_train, y_train) = load_data(img_dir_path, 300)\n",
    "x_train_norm = x_train / 255.0 # 입력은 0~1로 정규화\n",
    "\n",
    "\n",
    "print('x_train shape: {}'.format(x_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee6cdb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 불러와보자\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0]) # 가위(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089d0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "146aa50c",
   "metadata": {},
   "source": [
    "# 2. 딥러닝 네트워크 설계\n",
    "처음엔 성능을 고려하지 않고 예시에 나와있는대로 임의로 값을 대입했다. (하이퍼파라미터 조정 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b99d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 31,050\n",
      "Trainable params: 31,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D((2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a9840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9f8ab18",
   "metadata": {},
   "source": [
    "# 3. 딥러닝 네트워크 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5abab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 3s 12ms/step - loss: 12.5902 - accuracy: 0.4267\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0721 - accuracy: 0.8033\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.9300\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9933\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8.3072e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.3957e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f8c7c52e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ed6c9",
   "metadata": {},
   "source": [
    "### 🌷 학습 정확도 = 1.0으로 아주 잘 나옴을 알 수 있다.\n",
    "##### + 혹시 overfitting 된 것 아닐지 ..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ea72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56a89813",
   "metadata": {},
   "source": [
    "# 4. 테스트 하기\n",
    "## 4-1. test data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7cd5116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -uq \"test1/scissor (1).zip\" -d \"test1/scissor\"\n",
    "# !unzip -uq \"test1/paper (1).zip\" -d \"test1/paper\"\n",
    "# !unzip -uq \"test1/rock (1).zip\" -d \"test1/rock\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8b3ad7",
   "metadata": {},
   "source": [
    "##### train data와 비슷한 방식으로 진행된다.\n",
    "- 테스트 데이터도 마찬가지로 (다른) 300개의 데이터를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c93b6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여 resize\n",
    "s_path = './test1/scissor'\n",
    "resize_images(s_path)\n",
    "print('가위 이미지 resize 완료!')\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여 resize\n",
    "r_path = './test1/rock'\n",
    "resize_images(r_path)\n",
    "print('바위 이미지 resize 완료!')\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여 resize\n",
    "p_path = './test1/paper'\n",
    "resize_images(p_path)\n",
    "print('보 이미지 resize 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de6ab9d",
   "metadata": {},
   "source": [
    "##### * 경로 변경으로 부득이하게 load_data 함수 재정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98b98e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path, number_of_data):\n",
    "    # 가위(0), 바위(1), 보(2)\n",
    "    img_size = 28\n",
    "    color = 3\n",
    "    \n",
    "    # 이미지 데이터와 라벨(가위(0), 바위(1), 보(2)) 데이터를 담을 행렬(matrix) 영역 생성\n",
    "    imgs = np.zeros(number_of_data * img_size * img_size * color, dtype=np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    labels = np.zeros(number_of_data, dtype=np.int32)\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for file in glob.iglob(img_path + '/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 0 # 가위(0)\n",
    "        idx = idx + 1\n",
    "    \n",
    "    for file in glob.iglob(img_path + '/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 1 # 바위(1)\n",
    "        idx = idx + 1\n",
    "    \n",
    "    for file in glob.iglob(img_path + '/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 2 # 보(2)\n",
    "        idx = idx + 1\n",
    "    \n",
    "    print('학습 데이터(x_test)의 이미지 개수는 ', idx, '입니다.')\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dc30fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터(x_test)의 이미지 개수는  300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "img_dir_path = './test1'\n",
    "(x_test, y_test) = load_data(img_dir_path, 300)\n",
    "x_test_norm = x_test / 255.0 # 입력은 0~1로 정규화\n",
    "\n",
    "\n",
    "print('x_test shape: {}'.format(x_test.shape))\n",
    "print('y_test shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb495b33",
   "metadata": {},
   "source": [
    "## 4-2. 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf5abf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 16.1608 - accuracy: 0.3333\n",
      "test_loss: 16.16078758239746 \n",
      "test_accuaracy: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('test_loss: {} '.format(test_loss))\n",
    "print('test_accuaracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02471bcb",
   "metadata": {},
   "source": [
    "### 🧤 정확도 = 0.33 : 매우 낮음 -> 보완 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698b97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3772b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ab887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65caf0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ffd8cb8",
   "metadata": {},
   "source": [
    "## 5. 성능 보완하기\n",
    "\n",
    "1. 하이퍼파라미터 이용\n",
    "2. train 데이터 개수 늘리기 (300->1500) + 이미지 resize 하지 않기\n",
    "3. train 데이터 개수 늘리기 (300->1500)\n",
    "4. test 데이터 개수 줄이기 (300->30)\n",
    "5. test 데이터 변경하기 (아이펠 제공)\n",
    "\n",
    "## 5-(1) 하이퍼 파라미터 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ff617a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 28, 28, 3)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f0fe7",
   "metadata": {},
   "source": [
    "##### + 하이퍼파라미터도 마찬가지로 임의 조정이 아니라 여러 범위를 주었으면 더 좋을듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dd6a828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                32040     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                410       \n",
      "=================================================================\n",
      "Total params: 37,538\n",
      "Trainable params: 37,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1 = 16\n",
    "n_channel_2 = 32\n",
    "n_dense = 40\n",
    "n_train_epoch = 20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37d39d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 21.7159 - accuracy: 0.3233\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.8726 - accuracy: 0.7233\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.9000\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9667\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9967\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4.9811e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3.3549e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.9305e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.7603e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.6361e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.5336e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.4436e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.3534e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2722e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2002e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.1270e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.0801e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.9999e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.9168e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ee04f2400>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef3919",
   "metadata": {},
   "source": [
    "### 🌷 학습 정확도 = 1.0\n",
    "- 에포크는 6부터 1.0이 나와서 줄여도 된다고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "310219c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 16.3456 - accuracy: 0.3333\n",
      "test_loss: 16.3455753326416 \n",
      "test_accuaracy: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('test_loss: {} '.format(test_loss))\n",
    "print('test_accuaracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32f31d7",
   "metadata": {},
   "source": [
    "### 🧤 정확도 = 0.33\n",
    "- 그대로!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a5c079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9603a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da213fe",
   "metadata": {},
   "source": [
    "## 5-(2) 데이터 수 늘리기 + resize하지 않기\n",
    "\n",
    "- 애초에 원본 데이터 저장했으면 다시 다운로드 받을 일 없었음 ㅎㅎ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f784e7ba",
   "metadata": {},
   "source": [
    "### train data 수가 적다고 판단해 가위바위보 이미지를 각각 500개, 총 1500개로 늘렸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f625973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -uq \"original_train/scissor3.zip\" -d \"original_train/scissor\"\n",
    "# !unzip -uq \"original_train/paper3.zip\" -d \"original_train/paper\"\n",
    "# !unzip -uq \"original_train/rock3.zip\" -d \"original_train/rock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9721991b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지 파일 크기 확인\n",
    "s_path = './original_train/scissor'\n",
    "s_img = glob.glob(s_path + '/*.jpg')\n",
    "Image.open(s_img[0]).size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea36ae",
   "metadata": {},
   "source": [
    "### 이미지 크기를 조정하지 않았기 때문에 load_data_224()라는 함수로 새로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2405bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_224(img_path, number_of_data): # 데이터 숫자 바꿔주기\n",
    "    # 가위(0), 바위(1), 보(2)\n",
    "    img_size = 224\n",
    "    color = 3\n",
    "    \n",
    "    # 이미지 데이터와 라벨(가위(0), 바위(1), 보(2)) 데이터를 담을 행렬(matrix) 영역 생성\n",
    "    imgs = np.zeros(number_of_data * img_size * img_size * color, dtype=np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    labels = np.zeros(number_of_data, dtype=np.int32)\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for file in glob.iglob(img_path + '/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 0 # 가위(0)\n",
    "        idx = idx + 1\n",
    "    \n",
    "    for file in glob.iglob(img_path + '/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 1 # 바위(1)\n",
    "        idx = idx + 1\n",
    "    \n",
    "    for file in glob.iglob(img_path + '/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 2 # 보(2)\n",
    "        idx = idx + 1\n",
    "    \n",
    "    print('학습 데이터(x_train)의 이미지 개수는 ', idx, '입니다.')\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76d43e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터(x_train)의 이미지 개수는  1500 입니다.\n",
      "x_train_origin shape: (1500, 224, 224, 3)\n",
      "y_train_origin shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "img_dir_path = './original_train'\n",
    "(x_train_origin, y_train_origin) = load_data_224(img_dir_path, 1500)\n",
    "x_train_norm_origin = x_train_origin / 255.0 # 입력은 0~1로 정규화\n",
    "\n",
    "print('x_train_origin shape: {}'.format(x_train_origin.shape))\n",
    "print('y_train_origin shape: {}'.format(y_train_origin.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a886aa0",
   "metadata": {},
   "source": [
    "- 이미지의 개수, 크기가 각각 1500, 224x224 임을 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6323a21b",
   "metadata": {},
   "source": [
    "### 첫 번째 activation 함수를 relu가 아닌 softsign으로 변경했다.\n",
    "+ 이에 관한 설명은 따로 정리할 것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fda0fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 186624)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 36)                6718500   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 111       \n",
      "=================================================================\n",
      "Total params: 6,738,003\n",
      "Trainable params: 6,738,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 변경 가능한 하이퍼파라미터\n",
    "n_channel_1 = 32\n",
    "n_channel_2 = 64\n",
    "n_dense = 36\n",
    "n_train_epoch = 10\n",
    "\n",
    "# model 생성 시 input_size를 28이 아닌 224로 변경해야 함\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='softsign', input_shape=(224, 224, 3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d59e0446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 4s 54ms/step - loss: 3.3809 - accuracy: 0.7440\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 2s 44ms/step - loss: 0.0435 - accuracy: 0.9833\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 2s 44ms/step - loss: 0.0326 - accuracy: 0.9913\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 2s 44ms/step - loss: 0.0057 - accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 2s 44ms/step - loss: 6.5659e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 2s 44ms/step - loss: 1.8547e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 2s 44ms/step - loss: 1.3347e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 2s 44ms/step - loss: 9.6339e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 2s 44ms/step - loss: 7.4837e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 2s 44ms/step - loss: 6.1135e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ee03d4070>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_origin, y_train_origin, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2494a2",
   "metadata": {},
   "source": [
    "### 🌷 학습 정확도 = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38133be",
   "metadata": {},
   "source": [
    "### test data도 resize하지 않고 load_data_224() 함수에 대입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "787eb3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터(x_train)의 이미지 개수는  300 입니다.\n",
      "x_test_origin shape: (300, 224, 224, 3)\n",
      "y_test_origin shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "img_dir_path = './original_test'\n",
    "(x_test_origin, y_test_origin) = load_data_224(img_dir_path, 300)\n",
    "x_test_norm_origin = x_test_origin / 255.0 # 입력은 0~1로 정규화\n",
    "\n",
    "\n",
    "print('x_test_origin shape: {}'.format(x_test_origin.shape))\n",
    "print('y_test_origin shape: {}'.format(y_test_origin.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df44a318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 3.8100 - accuracy: 0.3533\n",
      "test_loss: 3.8099963665008545 \n",
      "test_accuaracy: 0.35333332419395447\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_origin, y_test_origin, verbose=2)\n",
    "print('test_loss: {} '.format(test_loss))\n",
    "print('test_accuaracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35965bd6",
   "metadata": {},
   "source": [
    "### 🧤 정확도 = 0.35\n",
    "- 아직도 너무 부족!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9806f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b083737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95302346",
   "metadata": {},
   "source": [
    "## 5-(3) resize하지 않고 데이터 수 늘리기\n",
    "##### 총 1500개의 train data, 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2215cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -uq \"my_train/scissor3.zip\" -d \"my_train/scissor\"\n",
    "# !unzip -uq \"my_train/paper3.zip\" -d \"my_train/paper\"\n",
    "# !unzip -uq \"my_train/rock3.zip\" -d \"my_train/rock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db53d183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  images to be resized.\n",
      "500  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "500  images to be resized.\n",
      "500  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "500  images to be resized.\n",
      "500  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여 resize\n",
    "s_path = './my_train/scissor'\n",
    "resize_images(s_path)\n",
    "print('가위 이미지 resize 완료!')\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여 resize\n",
    "r_path = './my_train/rock'\n",
    "resize_images(r_path)\n",
    "print('바위 이미지 resize 완료!')\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여 resize\n",
    "p_path = './my_train/paper'\n",
    "resize_images(p_path)\n",
    "print('보 이미지 resize 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8914e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터(x_test)의 이미지 개수는  1500 입니다.\n",
      "x_train shape: (1500, 28, 28, 3)\n",
      "y_train shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "img_dir_path = './my_train'\n",
    "(x_train, y_train) = load_data(img_dir_path, 1500)\n",
    "x_train_norm = x_train / 255.0 # 입력은 0~1로 정규화\n",
    "\n",
    "\n",
    "print('x_train shape: {}'.format(x_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678aed91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7204d922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 36)                57636     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 111       \n",
      "=================================================================\n",
      "Total params: 77,139\n",
      "Trainable params: 77,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "\n",
    "n_channel_1 = 32\n",
    "n_channel_2 = 64\n",
    "n_dense = 36\n",
    "n_train_epoch = 10\n",
    "\n",
    "# softsign으로 바꿈\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='softsign', input_shape=(28, 28, 3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b471db8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 1s 4ms/step - loss: 0.7243 - accuracy: 0.7287\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9373\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9733\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9973\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ee031a280>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0446f9a8",
   "metadata": {},
   "source": [
    "### 🌷 학습 정확도 = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c587d945",
   "metadata": {},
   "source": [
    "### test data는 기존 것 (resize x) 그대로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00961da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 2.6206 - accuracy: 0.4967\n",
      "test_loss: 2.620631456375122 \n",
      "test_accuaracy: 0.49666666984558105\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('test_loss: {} '.format(test_loss))\n",
    "print('test_accuaracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df51b09",
   "metadata": {},
   "source": [
    "### 🧤 정확도 = 0.49\n",
    "- 조금 올랐지만 역부족"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a1282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8afd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f771025e",
   "metadata": {},
   "source": [
    "## 5-4) 데이터 수 늘리기(1500) + 아이펠 test 데이터\n",
    "### test data의 질이 좋지 않을 수 있다 생각해 제공해주신 걸로 변경해주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3790f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -uq \"data.zip\" -d \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52334093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터(x_test)의 이미지 개수는  300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "img_dir_path = './data/test'\n",
    "(x_test, y_test) = load_data(img_dir_path, 300)\n",
    "x_test_norm = x_test / 255.0 # 입력은 0~1로 정규화\n",
    "\n",
    "\n",
    "print('x_test shape: {}'.format(x_test.shape))\n",
    "print('y_test shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78dfd3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.3442 - accuracy: 0.7033\n",
      "test_loss: 1.3441557884216309 \n",
      "test_accuaracy: 0.70333331823349\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('test_loss: {} '.format(test_loss))\n",
    "print('test_accuaracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e8fd38",
   "metadata": {},
   "source": [
    "### 🧤 정확도 = 0.70 !!!\n",
    "#### 드디어 60%가 넘었다\n",
    "- run 할 때마다 78% 넘을 때도, 60% 미만일 때도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dda574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5996c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55039741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dadf3b9e",
   "metadata": {},
   "source": [
    "*****************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad23e28",
   "metadata": {},
   "source": [
    "# 결론\n",
    "\n",
    "## >> 좀 더 정교한 많은 양의 train 데이터 + 뚜렷한 test data 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c0641d",
   "metadata": {},
   "source": [
    "*****************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ee21d2",
   "metadata": {},
   "source": [
    "## * 깨달은 점 *\n",
    "\n",
    "### 사실 크게 어렵거나 복잡한 내용은 아니지만 생각보다 accuracy가 너무 낮게 나와 오래 고생을 했다. 느낀점으로는\n",
    "\n",
    "#### 1. 원본 train data가 매우 정교해야 함\n",
    "    - 처음 찍은 300개의 데이터는 배경이 깔끔하지도 않았고, 손 모양을 이리저리 돌린 바람에 모델의 정교함이 떨어졌던 것 같다.\n",
    "    - 정교함 뿐 아니라 데이터의 수도 300 -> 1500으로 증가시킨 것이 효과적이었고, 4500개 찍으신 분의 결과를 들어보니 정확도가 90% 이상이라 하심 !!\n",
    "    - ** 결국 사진만 잘 찍어도 좋은 결과 나올 것 같다.\n",
    "    \n",
    "#### 2. 반복되는 작업으로  여러 폴더/파일들을 생성했는데, 이 때마다 파일명이 헷갈려서 애먹음\n",
    "#### 3. 하이퍼파라미터를 임의로 조정하지 않고, 여러 범위들을 주어 최적의 값을 추출하는 편이 요구됨\n",
    "#### 4. 초반에 resize(), load_data() 등 함수를 여러 번 반복해 정의하고 실행하였더니 정확도가 더 낮게 나온 것 같은데 연관이 있는지는 정확하게 모르겠다.\n",
    "#### 5. 코드가 길어서 그런가 실행할 때마다의 accuracy의 편차가 다소 큼\n",
    "#### 6. 생각보다 size 크기 변경은 큰 역할을 하지 않는구나"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269d220",
   "metadata": {},
   "source": [
    "*****************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17be8afb",
   "metadata": {},
   "source": [
    "## 🗣 Raw Data의 특성을 잘 깨달은 첫 Exploration 이었다 :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e764be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec830fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
